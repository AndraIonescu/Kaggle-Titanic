# Kaggle-Titanic
Trying out LightGBM on Kaggle's Titanic dataset
Data available here:

## [Kaggle-notebook.py](https://github.com/garethjns/Kaggle-Titanic/blob/master/Kaggle-Notebook.ipynb)
Introduction to preprocessing and preparing the data to use in LightGBM. 
See also: https://www.kaggle.com/garethjns/microsoft-lightgbm-0-795

## [run.py](https://github.com/garethjns/Kaggle-Titanic/blob/master/run.py)
Script to prepare data, grid search best model paramters, fit a robust ensemble on multiple data splits.  
Should only take <5 minutes to run and score 0.822 which places in the top 3% currentely.  
See also: https://www.kaggle.com/garethjns/microsoft-lightgbm-with-parameter-tuning-0-822
